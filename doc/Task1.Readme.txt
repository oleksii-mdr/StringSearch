========== TASK 1 ==========

Initial description
-------------------
Problem 1: What’s in a name?

As part of the implementation of a large international web site several features of the site need to be able to determine whether a text document contains a reference to a person. For example, one application is protecting the identity of users of the site. Another is to identify documents about well-known personalities.

Write a reusable component that can be used to determine whether a text document contains a name. When a document contains a name the component must return a list of offsets within the document of the first character of each name found.

You have available to you three text files containing names as follows, with a single name on each line in the file:
-	A list of surnames (family names)
-	A list of female first names
-	A list of male first names

To simplify the task you can define a name as a first name and a surname separated by a space. You can also assume that first names and surnames do not themselves contain spaces.
=============================

List of assumptions
-------------------
- "Text document" is .txt file with text that is stored in ASCII encoding, any work connected to using different encoding or endianness of the machine is out of scope for this program
- Text document is of limited size that can be loaded into memory at once. If this is not possible, a document must be split explicitly before (or while) processing. A program can be tweaked to take an offset parameter and read a stream. This can be used to process chunks of an infinitely large document
- Three text files with names are small in sizes, so can all fit into memory. This is usually a valid assumption, because number of names in one language is fairly limited to (perhaps) 100 000. If there are three documents, each containing 100 000 names, with each name of 10 chars longs, and each char takes around two bytes space(CLR uses UTF-16 by default), this gives: 3 * 100 000 * 10 * 16 < 6 MB
- As there is a requirement to return match positions in the input document, and no requirement to return match positions from the names documents, it make sense to simplify the task. Consider concatenating 3 documents with first and last names into one. This will provide a single source for string comparison instead of having 3. Keeping in mind the previous assumption, that the total size of 3 files take less then 6 MB of memory, all three document can fit in memory easily as a single unit
- Concatenation of small documents with names is an easy task and will be performed as part of the pre-processing in this program
- A match will use case insensitive comparison, i.e. Alice = ALICE = ALicE. Currently this is not configurable, but can be made so
- This problem can be generalised to a substring search problem with multiple patterns of variable lengths
- Length of an input document is significantly greater, than the lengths of documents with names
- Application will return a 0-based enumeration of indexes of all matches
- Unicode is not tested, and as this task will potentially be used in a multilingual environment this shall be considered as a next step. Potential problems are: calculating correct rolling hash code, endianness of the machine, direction of comparison (left-to-right or right-to-left), among others
- Files with names are allowed to have empty strings and wrapping spaces around names, for example see files in /data/task1 
- This application uses Rabin–Karp algorithm for multiple pattern matching. It runs in O(N+M) on average case, however, in worst case the performance is O(N^2). Faster algorithms can be used, but due to complexity and lack of time those algorithms have not been implemented
- Application allows a plugable architecture, it is fairly easy to add another search strategy by implementing an interface and running code with the new injected search implementation. Something working now(perhaps rather slow in the worst case) is much better than a non working (but potentially faster) solution

Solving the problem
-------------------
Input text length: n
Document with name lenght: m
Input lenght is much greater than the length of document with names: n >> m

Naive approach:
Tokenize input by words (map-emit function). For each word in the input document, check if the word is in the names documents. Space complexity: O(n + m). Time complexity: O(n * m) = O(n*m) = O(n^2) - perhaps a slightly overestimated upper boundary on computational complexity as n >> m, but still this algorithm runs in a quadratic time. 

Rabin–Karp algorithm
If matching patterns can be preprocessed. Given a rolling hash table with patterns, it is possible to quickly find if a substring has a matching pattern. Space complexity: O(n + m). Time complexity: O(n + m) on average, in worst case, where no matches found, it is O(N*M) = O(N^2)

Other algorithms to consider
---------------------------

Aho–Corasick string matching algorithm
 - more complex
 - has better guaranteed worst case complexity O(N+M)